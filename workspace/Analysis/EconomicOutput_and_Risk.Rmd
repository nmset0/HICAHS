---
title: "Economic Output and Risk Factors"
author: "Nathan Seto"
output: pdf_document
---

```{r, include = FALSE}
rm(list=ls())
library(knitr)
library(tidyr)
library(tidyverse)
library(readr)
library(ggcorrplot)
library(dplyr)
opts_chunk$set(echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, tidy = TRUE)
```

## What is the relationship between health risk concentrations and economic output?

#### Calculate correlations between environmental exposures and farm sales (and/or other econ. variables) to understand economic linkages.
$\\$

To see coefficients and significance, follow this link: [https://nseto.shinyapps.io/correlation_econoutput_environmentalrisk/]. 
$\\$
The values used as variables of economic output are listed below. The predictor variables are all the variables in each data set that are not in the following list of variables. Variables ending in "\$_operation" denote "dollars per operation".
$\\$
```{r}
output_risk_combined <- read_csv("~/internship/workspace/Analysis/output_risk_combined.csv")

output_risk_combined <- output_risk_combined |> mutate(across(everything(), ~ gsub(",", "", .)))

cols <- names(output_risk_combined)[grepl("income|sales|farm_sales|income_net|commodity_totals|crop_totals_sales", 
                                                   names(output_risk_combined), ignore.case = TRUE)]

output_risk_combined <- output_risk_combined |> mutate(across(all_of(cols), as.numeric))

output_risk_combined <- output_risk_combined |>
  mutate(across(where(is.character), ~{
    if(any(grepl("\\d+", .x))) {
      cleaned <- gsub("[^0-9.-]", "", .x)
      as.numeric(cleaned)
    } else {
      .x
    }
  }))

output_environmentalRisk <- output_risk_combined  |>
  select(matches("farm_sales_|drought|wildfire|Cold\\.Wave|tornado|ice\\.storm|winter\\.weather|strong\\.wind|hail|heat\\.wave|avalanche|Landslide|lightning|income|sales|farm_sales|income_net|commodity_totals|crop_totals")) |> select(where(is.numeric))

output_environmentalRisk[is.na(output_environmentalRisk)] <- 0

good_cols <- grep("income|sales|farm_sales|income_net|commodity|crop", 
                      names(output_environmentalRisk), 
                      ignore.case = TRUE)

bad_cols <- grep("cattle_incl_calves_operations_with_sales|cattle_incl_calves_sales_measured_in_head|hogs_operations_with_sales|hogs_sales_measured_in_head|chickens_broilers_operations_with_sales|chickens_broilers_sales_measured_in_head", 
                     names(output_environmentalRisk), 
                     ignore.case = TRUE)

# Subset while excluding unwanted columns
subset_df <- output_environmentalRisk[, setdiff(good_cols, bad_cols), drop = FALSE]

list(names(subset_df))
```
$\\$

##### Methods
$\\$
I started this process by collecting separate data sets for all counties in the states covered by HICAHS from the United States Department of Agriculture agricultural census database. I then merged all these data sets into a single file. Since the variables were in rows, I pivoted the data set so the variables were made into columns. Following this, I merged the data containing natural disaster/weather variables, creating the complete data I desired to work with. See 'Processing\\output_Risk.R' for specific methods. Correlation coefficients were reached by taking one predictor and calculating the Spearman correlation coefficient and p-value between the remaining variables. This was done for all 17 response variables above. These values were then entered into a table to be displayed. To create the correlation plots found below, the original data set was split into 12 data sets by the type of natural disaster/weather factor, then correlations were calculated for each pair and graphed. The 17 response variables are identical throughout all 12 data sets. All work was completed using R and RStudio.


##### The Correlations
$\\$
Most of the correlations found were between 0.50 and 0.76, meaning economic output has a moderate to decently strong positive correlation with environmental risk factors used in this analysis. `Commodity Total Sales Measured in Dollars` had the highest correlations, almost reaching 1. This is analogous to the assumption that agricultural production and output would be hindered by increased damaging environmental effects.

Similar results are found using Spearman's correlation coefficient.


##### Significance
$\\$
Many correlations this analysis provided were significant (p < 0.05). A large number of p-values in the table are shown as zero. This means either the p-value is, in fact, zero, or very nearly zero. P-values equal to zero mean that the result is statistically impossible to occur under the null hypothesis. The number of p-values that are shown as zero is alarming, which brings to question the methods of testing I used or the structure of the data. However, I did use 'cor.test()' whose results I have no reason to question the validity of.


##### Correlograms
$\\$
Below are a series of correlation plots between variables of economic output and different weather/natural disaster predictors. The main focus is the rectangle towards the center of the plots, more prominent in some plots than others. The disaster/weather variables are naturally correlated with each other a majority of the time. The response variables are naturally correlated with each other to some degree. This is to be expected.
$\\$
```{r, fig.width = 9.5, fig.height = 10}
risk_types <- c("drought", "wildfire", "Cold\\.Wave", "tornado",
                "ice\\.storm", "winter\\.weather", "strong\\.wind", "hail",
                "heat\\.wave", "avalanche", "Landslide", "lightning")

risk_dfs <- list()

for (risk in risk_types) {
  clean_risk_name <- gsub("\\\\", "", risk)

  risk_dfs[[clean_risk_name]] <- output_environmentalRisk[, grepl(risk, names(output_environmentalRisk), ignore.case = TRUE)] |> cbind(subset_df)
}

for (i in names(risk_dfs)) {
  assign(i, risk_dfs[[i]])
}

source("C:/Users/natha/OneDrive/Documents/internship/workspace/Analysis/create_correlogram_function.R")

N <- c("drought", "wildfire", "Cold.Wave", "tornado", "ice.storm", "winter.weather", "strong.wind", "hail", "heat.wave", "avalanche", "Landslide", "lightning")
generate_corr_plot(N)

print(drought_corrplot)
  print(heat.wave_corrplot)
    print(wildfire_corrplot)
      print(winter.weather_corrplot)
        print(Cold.Wave_corrplot)
          print(hail_corrplot)
            print(ice.storm_corrplot)
              print(strong.wind_corrplot)
                print(tornado_corrplot)
                  print(lightning_corrplot)
                    print(avalanche_corrplot)
```

##### Problems with Data Structure
$\\$
Many of the columns are filled with NAs, but I am lead to believe this is because some factors simply do not happen in certain states/counties. This could also be due to how to data was transformed into a clean data set; further investigation is required. When processing the data prior to calculating correlations, I changed all NAs to 0, which may have caused faulty evaluation of correlations and/or significance as well. I chose to do this because many variables take the frequency or exposure from different variables, so if a county never gets any events of such then frequency, exposure, or any related factor is virtually nonexistent, and the data entry is entered as NA, and is therefore changed to zero by my data cleaning, which is why converting those value is a valid procedure. Changing NAs to zero also make it easier for R to calculate correlation coefficients. Keeping NA values can lead to the deletion of rows depending on the requirements of the algorithms used. Since each row is a different county, I want to avoid this as much as I can in order to have the most complete data set possible (I have not removed any rows at this point). Mean/Median or K-Nearest Neighbor imputation was out of the question for this data. Doing so would have altered recorded fact and created falsehoods, adding bias that would otherwise not be present and negating the overall plausibility of the analysis. Removing rows without complete observations was  not favorable for similar reasons. Since the purpose is to find correlations between variables and not related to machine learning at this time, the optimal method was converting NAs to 0 values to create complete observations.



